[
  {
    "objectID": "media/Dolendar_System_Requirements.html",
    "href": "media/Dolendar_System_Requirements.html",
    "title": "Table of Content",
    "section": "",
    "text": "Dolendar System Requirements\nRuilin Wu\n\n\nTable of Content\n\n\n\n\n\n\n\n\nTable of Content\n\n\n\n\n\n\nIntroduction\nOutlines the purpose and overview of the Requirements Specification.\n2\n\n\nExecutive Summary\nA concise recap of the Dolendar’s key aspects and its overarching goals.\n3\n\n\nApplication Context / Environmental Constraints\nDetails of the application and the operating platforms.\n3-4\n\n\nFunctional Requirements\nSpecify the essential actions and features the application must provide.\n4-7\n\n\nNon-functional Requirements\nDetail the performance and quality for system designers and programmers.\n8\n\n\nOther Requirements\n\n9\n\n\nGlossary\nAdditional requirements still need to be mentioned.\n\n\n\nDefines specialized terms throughout the document.\n\n9\n\n\nAssumptions / Risks\nPotential uncertainties and challenges that could impact Dolendar.\n10\n\n\nPriorities / Implementation Phases\nOrder and timeline for the application’s development stages\n10\n\n\nFuture Directions and Expected Changes\nHints at the application’s evolution and potential updates\n11\n\n\n\n\n\n\n\n\nIntroduction\nThis document outlines the software requirements for Dolendar, a productivity suite of software developed by the INF43 Software Engineering group under the commission of Dom Dones, president and founder of DoMore Software Corp.\nDolendar integrates a calendar application and a to-do list manager, aimed at helping users enhance work productivity and personal time management, and understand the impact of procrastination on their scheduling.\n\n\nExecutive Summary\nDolendar is a sophisticated productivity tool that redefines traditional scheduling by integrating to-do lists with calendar functions. It allows users to craft detailed to-do lists while aligning and displaying their tasks alongside scheduled events, providing a holistic view of their commitments. This feature encourages frequent interaction with the calendar, fostering a proactive approach to task management and highlighting the effects of unfinished tasks on overall schedules. By clearly showing how delays can impact one’s time, Dolendar differentiates itself from ordinary organizational software, serving not just as a work aid but as a comprehensive system for managing personal goals and daily activities.\nDolendar offers both a personal-use version and an enterprise version. The personal version is free and equipped with all basic features, and a subscription version can support data storage and synchronization. Businesses can opt for the enterprise version, which offers additional functionalities tailored to professional needs and is accessible through corporate engagement with DoMore Software.\nThe design philosophy behind Dolendar prioritizes simplicity and user-friendliness, recognizing the necessity for an intuitive user experience amidst a competitive market. It is meticulously developed to meet high standards of usability, privacy, and data protection, thereby ensuring reliability for users. Designed for seamless integration with current digital ecosystems, Dolendar complements existing calendar applications and is compatible with cloud services, allowing immediate productivity enhancements without significant changes to existing workflows.\nDolendar goes beyond scheduling; it’s an ally in time management, bridging the gap between digital efficiency and the intricacies of everyday living, enabling users to reclaim control over their time with confidence and ease.\n\n\nApplication Context / Environmental Constraints\nDolendar software is crafted to serve many environments, demonstrating versatility and adaptability.\n\nIt is designed to streamline and enhance the productivity of business and office settings, where individuals and teams alike can efficiently manage their schedules, meetings, and collaborative endeavors. Within these settings, the software will facilitate team-based functionality, allowing for an intuitive interface where the team’s admin can assign tasks and make announcements with ease.\n\nDolendar extends its utility to personal use, where users can organize and track their individual goals, daily tasks, family events, and various other personal activities, making it an indispensable tool in the realm of personal organization.\n\nIt supports an on-the-go lifestyle, enabling users to access and manage their schedules and tasks with the same efficiency outdoors or while traveling.\n\nThe developmental blueprint for Dolendar spans across mobile and desktop platforms. The mobile application is being developed to serve both iOS and Android operating systems for phones and tablets. This version promises a responsive design, capable of adapting to a multitude of screen sizes and orientations for optimal functionality. Following the mobile release, a desktop application is set to be introduced to serve users on Windows, macOS, and Linux, catering to the needs of the desktop environment.\nWith regards to operating system support, the mobile application will be compatible with the system version for iOS and Android at the time of the application release and one prior. The desktop version will match up to the prevailing system versions of Windows, macOS, and Linux at the time of its release, ensuring broad accessibility.\nDesign considerations for Dolendar are centered around a modern, elegant, and sleek user interface (UI) design, emphasizing ease of use and intuitive interactions to reduce friction for the end-user. The UI will be inclusive, accommodating both dark and light modes with customizable color themes to not only cater to user preferences but also to ensure accessibility for users who are color-blind.\nCertain constraints dictate the software’s architecture to ensure it aligns with contemporary expectations. It is imperative that the software syncs with prevalent calendar services such as Google Calendar and Apple iCloud Calendar, negating the need for a proprietary calendar system within Dolendar. Emphasis is placed on adopting modern, secure, and robust programming languages and frameworks to fortify the software’s security, efficiency, and maintainability. A cloud-based backend service is also in the blueprint, designed to manage the intricacies of syncing and collaboration features in line with a subscription-based business model.\nIn the selection of programming languages, the INF43 Software Engineering group has been granted the liberty to choose the most fitting language for the development of this application, ensuring the final product is built on a foundation that maximizes its potential.\n\n\nFunctional Requirements\nDolendar is a combination of a to-do list app and a calendar, and it is designed to enhance work productivity and personal time management. It integrates various functionalities to address human psychology and procrastination, aiding users in achieving personal and professional goals.\nCore Functionalities\n\nEvent and Task Management: Users can create, modify, and delete tasks and events. Tasks are the user’s to-do items, activities or goals planned to be completed; events are planned events, such as meetings or courses, fixed schedules or flexible events. This feature includes setting titles, descriptions, and other relevant details for tasks and events. Tasks are more flexible and can be adjusted around fixed events in the calendar.\n\nTime Allocation for Tasks: Users assign an estimated duration to each task, which the system then integrates into the user’s calendar. This will allow users to have their tasks and events intersected, which helps visualize the time allocated to each task and manage the day more efficiently.\n\nDynamic Task Adjustment: Based on the user’s progress and upcoming deadlines, tasks dynamically change in the calendar. If a task is not completed within the expected time, it is automatically rescheduled, affecting the scheduling of future tasks. This feature highlights the impact of procrastination and helps users better manage their time.\n\nIf a user marks a task as done before the deadline, it will not affect subsequent tasks; however, if a task exceeds the deadline, all subsequent tasks will be delayed accordingly. Once an overdue task is completed, all subsequent tasks return to their normal schedule at the current time.\n\n\nSub-tasks Creation and Management: Allows breaking down large tasks into smaller, more manageable sub-tasks. Each sub-task can have its own description, duration, and completion status. This feature aids in organizing complex tasks and tracking progress on individual components.\n\nCalendar and To-do List Views: Separate views for the calendar and the to-do list, providing different perspectives on the user’s schedule. The calendar view displays both tasks and events chronologically, while the to-do list view focuses on tasks alone. Users can toggle between views based on their preference or need.\n\nTask Tags and Filters: Users can tag tasks and apply filters based on time windows and tags. This feature enhances the organization of tasks by categorizing them (like “work”, “personal”, etc.) and allows users to focus on specific types of tasks within certain time frames using filters.\n\nSyncing: The free version of the software stores data exclusively on the local device and lacks the ability to synchronize across multiple devices. However, the personal paid version or the enterprise edition includes a syncing feature, allowing users to access their personalized settings and information on different devices.\n\nTeam Collaboration: Designed for team use, this feature enhances task distribution and synchronization among team members.\n\nTask Assignment and Notification:\n\nTeam admins can assign tasks to members.\n\nMembers receive notifications and see these tasks integrated into their personal calendars.\n\n\nSynchronization:\n\nThe sync feature ensures that updates made to tasks are immediately reflected on all team members’ devices. This promotes effective collaboration and keeps the team aligned.\n\n\nPrivacy of Tasks and Events:\n\nTasks and calendar items can be set as either public or private. Private tasks or events are visible in the calendar as occupied time slots, but their content remains confidential. Team members can see that there is a private task at a certain time but cannot view its specifics.\n\n\nVisibility and Access:\n\nEvery team member has visibility into everyone else’s task list and calendar. Private tasks or events are visible in the calendar as occupied time slots, but their content remains confidential.\n\nTeam members can see that there is a private task at a certain time but cannot view its specifics.\n\nThis includes viewing the completion status of tasks.\n\nAny team member can add an item to another member’s task list once a day, further enhancing collaborative planning and task distribution.\n\n\n\nUse Case:\nUse Case 1: Managing Personal Tasks (Primary Actor: Individual User)\nBasic Flow:\n\nUser logs into Dolendar.\n\nUser creates a new task, assigning a title, description, and estimated duration.\n\nThe system integrates the task into the user’s calendar based on available time slots.\n\nUser marks the task as completed after finishing it.\n\nSystem updates the calendar, moving upcoming tasks forward.\n\nAlternative Flow:\n\nUser attempts to add a task with an unrealistic duration.\n\nSystem prompts a warning about the duration conflicting with other scheduled events.\n\nUser adjusts the task duration or reschedules other events.\n\nException Flow:\n\nUser forgets to mark a task as completed.\n\nSystem keeps the task in the calendar, causing a shift in subsequent tasks.\n\nUse Case 2: Collaborative Task Management (Primary Actor: Team Member; Secondary Actor: Team Admin)\nBasic Flow:\n\nTeam Admin logs into Dolendar and accesses the team calendar.\n\nTeam Admin assigns a task to a Team Member, specifying details and deadline.\n\nThe system notifies the Team Member and adds the task to their personal calendar.\n\nTeam Member completes the task and marks it as done.\n\nSystem updates the team calendar showing the task’s completion.\n\nUse Case Diagram:\n\n\n\nNon-functional Requirements\n\n\n\n\n\n\n\nUsability\nThe UI/UX should be modern, elegant, and stylish, designed for easy input and editing of tasks and events. Users should be able to easily distinguish between the calendar view and the todo list view. Adding tasks from the todo list to the calendar should not cause confusion but should remain neat and orderly. Users should be able to input and schedule tasks with minimal effort.\n\n\n\n\nSecurity\nUser data should be protected during transmission and at rest using modern encryption protocols, especially for the enterprise version and all long-range versions, ensuring the security of personal and enterprise data without leaks and protecting user privacy.\n\n\nReliability\nTo ensure data integrity, in addition to the sync and cloud data storage features available in the subscribed personal and enterprise versions, the accuracy and retrieval of data saved on local devices should not be compromised.\n\n\nFlexibility\nUsers should have the capability to customize the theme by specifying RGB values, enhancing personalization and improving accessibility for individuals with color vision deficiencies. The platform offers a configurable setting that allows users to select their preferred calendar layout, be it weekly or daily. Additionally, the default duration assigned to new tasks is fully adjustable, ensuring users can tailor their scheduling to fit their unique requirements.\n\n\nMaintainability\nThere needs to be long-term maintenance of data information.Ensure that updates to the application can be rolled out without significant downtime or data migration issues.\n\n\nPerformance\nThe application needs to be responsive with quick response times, especially since it combines a calendar and to-do list, which are sensitive to time. The software needs to manage the relationship between overdue tasks and future tasks, which requires the software to focus on updating tasks.\n\n\n\n\n\nOther Requirements\nClient Engagement:\nKeep the client involved throughout the development process for feedback and iterations on the product design and features.\nBudgets:\nThe total budget offered by DoMore Software Corp. is two million dollars. There is a million dollars for the mobile version of the application and another million upon completion of the desktop application.\nSubscription:\nThe personal use version is completely free for local devices, but does not include any synchronization updates or storage. Subscriptions are voluntary and require the customer’s consent. The business version needs to communicate with DoMore Software Corp. and is a paid service.\nAppearance:\nThe UI is expected to be modern, elegant and sleek appearance to attract the users. Users can choose dark mode or light mode with customizable color themes., but there is currently no option for theme selection. It is available for users to choose different colors for tasks by default.\n\n\nGlossary\n\n\n\n\n\n\n\nTask\nAn entity for the todo list feature and will be assigned to different durations.\n\n\n\n\nSub-task\nSeveral breakdown parts for a major task\n\n\nEvent\nAn entity for the calendar feature. Scheduled activities that occur at a specific time, such as classes or meetings, as opposed to tasks.\n\n\nTag\nKeywords or phrases that can be attached to tasks to categorize them and facilitate filtering.\n\n\nTime Window Filter\nFeatures in Dolendar that allow users to set specific time frames during which certain tagged tasks should be focused on.\n\n\nSyncing\nUsers’ data are stored on a cloud server, enabling access across multiple devices and collaboration with others.\n\n\nUser Interface (UI)\nThe interaction between the user and a digital device or software application, includes all the visual elements.\n\n\n\n\n\nAssumptions / Risks\nThere is no server cost for the free personal use version. The paid version gives users’ syncing capabilities, DoMore Software hosts the cloud syncing service. Assuming the user has a basic understanding of to-do lists and digital calendars and is seeking productivity enhancements and solutions for procrastination through the application.\nThe risks associated with Dolendar include potential financial risks due to market competition and whether the budget is sufficient. There are many calendar or to-do list applications on the market, including Google and Apple, so there is significant competition. Additionally, there is a risk associated with the users, who may not fully engage with the task management system. The most important risk stems from data, requiring robust security measures to prevent leaks. Dolendar involves personal privacy data and may contain confidential or proprietary documents from different companies.\n\n\nPriorities / Implementation Phases\nTimeline:\n\n\n\n\n\n\n\nNovember 3rd, 2023\nSubmission of the preliminary Dolendar System Requirements Specification document, excluding functional requirements and use cases.\n\n\n\n\nNovember 17th, 2023\nCompletion of the Dolendar System Requirements Specification, inclusive of functional requirements and use cases.\n\n\nJanuary 7th, 2024\nLaunch of the initial prototype of Dolendar, with subsequent versions to be released through monthly iterations.\n\n\nNovember, 2024\nThe release of the Dolendar mobile application.\n\n\nApril, 2025\nThe debut of the Dolendar desktop application.\n\n\n\nImplementation:\nMr. Dones emphasized that the prototype should have a new version updated monthly after the initial launch, and he also hopes to be involved in the design of the UI. The priority is to spend one year developing the application for iOS and Android systems on both mobile phones and tablets. Then, use the following six months to transition the mobile version to support desktop environments, including macOS, Windows, and Linux, allowing Dolendar to be used on desktop platforms as well.\n\n\nFuture Directions and Expected Changes\nThe expected changes are to enhance team functionalities for task sharing, collaboration, and management. Beyond the current team features, more discussable and joinable functions will be endowed in the enterprise and individual subscription versions.\nDolendar’s future direction is to update and refine some details of the software continuously. In the future, it may expand to provide users with more data for reference regarding their productivity and efficiency, as well as the extent of their procrastination. The metrics include graphs, rankings, and other metrics, as well as displays of each task’s completion status and more advanced reminders. The Dolendar platform anticipates future expansion and integration, supporting more systems and versions, as well as creating desktop quick-tips like Apple’s widgets. It also aims to support more external calendar synchronization, including Microsoft Outlook, but currently, it is only Apple Calendar and Google Calendar. Moreover, an essential part of the future direction is to consider supporting and aiding more people with disabilities in advancing accessibility."
  },
  {
    "objectID": "media/Stats170A_a2.html",
    "href": "media/Stats170A_a2.html",
    "title": "Abstract",
    "section": "",
    "text": "Analyzing Factors Related to Conferences Publication\nShuyi Chen, Ruilin Wu\n\nAbstract\n\nThis study examines how National Science Foundation (NSF) and National Institutes of Health (NIH) funding correlates with computer science conference publications from 2020 to 2024. After integrating open-source data with an existing database, we identified 1,840 principal investigators across 213 institutions. At the PI level, funding shows a weak relationship to publication counts (R² = 0.00174). In contrast, institution-level funding strongly predicts publication productivity (adjusted R² = 0.733). Incorporating regional interactions further improves explanatory power (adjusted R² = 0.8068), revealing a lower funding-to-publication “return” in the South compared to the Midwest. While the findings underscore funding’s importance institutionally, causal inferences are limited, and longer timelines may be needed to capture the full effect of recent grants.\n\nIntroduction\n\nConducting research and publishing findings are essential for advancing the field of computer science, and each study requires substantial financial support. Analyzing adjusted publication counts, which consider the number and ranking of authors in each paper, motivates us to examine the funding sources behind these publications. NSF and NIH datasets are processed separately, then merged after extracting principal investigator (PI) names and awarded funding. To maintain consistency, funding amounts for PIs with multiple awards are aggregated. Finally, the organized NSF and NIH datasets are merged with our existing cleaned database regarding the Computer Science field to explore potential correlations between the funding amounts received by principal investigators and their publication counts. This analysis aims to provide a deeper understanding of how research funding influences publication output in the field of computer science.\n\nStatistical Methods\n\nFrom 2020 to 2024, a total of 34,147 principal investigators (PIs) received funding from the National Science Foundation (NSF), while 76,219 PIs were funded by the National Institutes of Health (NIH) across various research fields worldwide.\nOur existing cleaned dataset contains the information of 17,837 principal investigators. After matching these records with the existing cleaned dataset, 1,737 PIs from NSF were identified. Their average total funding was $1,356,554, with a mean total adjusted publication count of 7.31. Similarly, 211 PIs from NIH were matched, receiving an average total funding of $2,788,723, with a mean total adjusted publication count of 5.07. The adjusted publication counts are right-skewed, with most PIs and institutions having low counts, while a few contribute significantly more.\nAfter merging the NSF and NIH awarded principal investigators (PIs), a total of 1,840 distinct PIs from 213 different institutions were identified. Their average total funding was $1,600,410, with a mean total adjusted publication count of 7.01. Total funding (log scale) follows a normal-like distribution, with PIs receiving mid-range amounts and institutions exhibiting greater variability. After filtering only US institutions to explore geographical factors, there are 158 institutions that received NSF and NIH funding in the past five years.\nTo assess the relationship between funding amounts and total adjusted publication counts, we employ a linear regression model for further analysis. Linear regression allows us to determine the extent to which funding influences research output by estimating the strength and direction of the association between funding and publication counts. The comparative analysis is conducted at two levels: the principal investigator(PI) level and the institution level. At the PI level, we examine how an individual researcher’s total awarded funding relates to their adjusted publication count. At the institution level, we aggregate the funding and the adjusted publication counts across institutions to analyze how research funding affects overall publication counts at a broader scale. Additionally, states of the institutions are being grouped into broader geographic regions: Northeast, Midwest, South, and West.\n\nResults\n\nLinear Regression Model 1: Total Adjusted Publications on Total Funding - Principle Investigator (Left)\nLinear Regression Model 2: Total Adjusted Publications on Total Funding - Institution (Right)\nModel 1 shows that at the PI level total funding is a very weak predictor of the total adjusted publication count. The estimated intercept is 6.863, meaning that with zero funding, an individual is predicted to have about 6.863 adjusted publications. The coefficient for total funding is 9.336e-08, indicating that an increase of $1,000,000 in funding is associated with an increase of roughly 0.093 publications. However, this effect is only marginally significant (p = 0.0737), and the model explains just 0.17% of the variance in publication counts (R-squared = 0.00174). Overall, funding does not appear to be a strong predictor of publication productivity at the PI level.\nModel 2 reveals that higher funding at institutional levels are strongly associated with increased publication productivity. Specifically, for every additional dollar of funding, the model predicts an increase of approximately 4.277e-06 in the total adjusted publication count. In more interpretable terms, an increase of $1,000,000 in funding is associated with an increase of about 4.277 adjusted publications. An adjusted R-squared of 0.733 indicates that roughly 73.3% of the variability in publication productivity is explained by differences in funding levels. Moreover, the F-statistic of 435.4 (p-value &lt; 2.2e-16) demonstrates that the overall model is statistically significant, confirming that funding is a very important predictor of publication output.\nLinear Regression Model 3: Total Adjusted Publications on Funding by Region (Interaction Model)\n\n\nModel 3 introduces an interaction between total funding and region, capturing whether the slope of funding’s effect on publications differs by region. Two of these interactions (Northeast and West) are not significant, however, region South exhibits a significant negative interaction term (-2.527e-06, p = 0.00015), each additional dollar of funding yields fewer publications compared to the Midwest. With an adjusted R-squared 0.8068, Model 3 explains about 80.7% of the variance in total adjusted publications—an improvement over a non-interactive model. These results suggest that while funding strongly predicts publication output at the institutional level, its effect can vary by region, with the South showing a notably smaller increase in publications per additional dollar of funding.\n\nDiscussion\n\nThe linear regression analyses reveal contrasting relationships between funding and adjusted publication counts at different levels of aggregation. At the principal investigator level, total funding explains very little of the variance in publication output, suggesting that individual productivity is more strongly influenced by factors such as research team size, institutional resources, collaborative networks, and disciplinary publishing norms. In contrast, institution-level analyses indicate a robust positive association between funding and publication productivity: higher funding generally translates into more adjusted publications. This likely reflects that sufficient financial resources enable improved research infrastructure, additional personnel, and stronger collaborative networks—factors that collectively foster a higher volume of publications. When regional factors are incorporated via an interaction of funding and region, the model’s explanatory power improves. Notably, the slope for the South is significantly lower than that of the baseline region, implying that an additional dollar of funding in the South yields fewer publications compared to the baseline. Meanwhile, the Northeast and West do not differ significantly from the Midwest. Although these regional differences are statistically meaningful, funding itself remains the primary predictor of publication output at the institutional level.\nDespite these insights, the analyses do not establish a causal link: higher funding may lead to more publications, but institutions with a strong track record may also be more competitive in securing grants. Additionally, some awards may not bear fruit immediately due to the long timeline needed for project completion and subsequent publication. Future studies could extend the timeframe, investigate the quality of published research, examine discipline-specific publishing norms, and explore longer-term funding effects to gain a more comprehensive understanding of how funding influences publication outcomes in computer science."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Phone Number: 5035488226\nEmail: ruiliw5@uci.edu"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "",
    "text": "Phone Number: 5035488226\nEmail: ruiliw5@uci.edu"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A Little Secret\nI built an interactive AI chatbot platform designed specifically for children in three age groups: Ages 5–7, 8–12, and 13+. The platform is powered by OpenAI’s ChatGPT API and enhanced with Retrieval-Augmented Generation (RAG) to deliver age-appropriate, context-aware responses.\nTo ensure safety and personalization, the chatbot asks for the child’s age and region at the start of the conversation. This allows it to tailor its responses based on developmental stage and local relevance—providing a more thoughtful and responsible AI experience for kids.\nVisit A Little Secret"
  },
  {
    "objectID": "projects.html#project-1",
    "href": "projects.html#project-1",
    "title": "Projects",
    "section": "",
    "text": "A Little Secret\nI built an interactive AI chatbot platform designed specifically for children in three age groups: Ages 5–7, 8–12, and 13+. The platform is powered by OpenAI’s ChatGPT API and enhanced with Retrieval-Augmented Generation (RAG) to deliver age-appropriate, context-aware responses.\nTo ensure safety and personalization, the chatbot asks for the child’s age and region at the start of the conversation. This allows it to tailor its responses based on developmental stage and local relevance—providing a more thoughtful and responsible AI experience for kids.\nVisit A Little Secret"
  },
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2\nCapstone Project – Delayed Antibiotics Administration\nCollaboration: Children’s Hospital of Orange County (CHOC)\nDuration: January 2025 – June 2025\nCollaborated with CHOC to develop a data-driven predictive model identifying and classifying the severity of delayed antibiotic administration in pediatric patients. The goal was to assist clinicians in proactive intervention, improving patient outcomes and hospital efficiency.\nMy Contribution:\n\nData Engineering: Engineered an ETL pipeline to consolidate and clean pediatric antibiotic data, foundational for robust feature engineering and predictive modeling.\nModel Development: Led the development and optimization of a Random Forest model to classify delay severity. Performed hyperparameter tuning, feature analysis, and benchmarked against other statistical models.\nEvaluation & Communication: Conducted rigorous model evaluation using ROC curves and confusion matrices, effectively communicating performance and insights.\nCollaboration & Management: Collaborated closely with clinical stakeholders for requirements and validation; managed project codebase and documentation on GitHub for team collaboration.\n\nVisit project site"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3\nBreast Cancer Recurrence Prediction\nThis project explores factors influencing breast cancer recurrence using Bayesian Logistics modeling and predictive analytics.\nView detailed report"
  },
  {
    "objectID": "projects.html#project-4",
    "href": "projects.html#project-4",
    "title": "Projects",
    "section": "Project 4",
    "text": "Project 4\nAnalyzing Related Factors to Computer Science Conferences Publications\nThis project investigates key factors associated with publication output in computer science conferences.\nBegan by processing and preparing the data, including thorough data cleaning, wrangling, and mining. Then gathered and organized open-source data in JSON format from NSF and NIH, enabling a deeper analysis of how various factors impact the number of conference publications.\nView data processing and cleaning report\nView finalized data report"
  },
  {
    "objectID": "projects.html#project-5",
    "href": "projects.html#project-5",
    "title": "Projects",
    "section": "Project 5",
    "text": "Project 5\nDolendar System Requirements\nThis project involved developing a comprehensive report tailored to the client’s specific needs and requirements. After a focused two-hour consultation, I carefully synthesized the client’s input and compiled all key insights into a well-structured document.\nView full report"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Poster Presentation\n2025 UCI Undergraduate Research Symposium poster presentation finalist.\nTheme: Human Experience and Expression\nTitle: Examining the Impact of an AI-powered Writing Platform in Upper-division Engineering Courses\nPoster\n\n\nResearch Experience\nResearch Assistant, UCI Digital Learning Lab\nSummer 2024 – Present\nWorking under Dr. Mark Warschauer, I’ve contributed to multiple education-focused research projects at the intersection of learning science and AI.\n\nPapyrus AI Project (January, 2025 – Present):\n\nCurrently supporting research on an AI-powered writing support system designed to improve students’ writing skills and learning outcomes. My work involves data cleaning, exploratory analysis, and evaluating usage patterns across diverse student populations.\n\nConverse to Learn Project (June, 2024 – 2025):\n\nParticipated in data collection and annotation for a project exploring how conversational agents can enhance student engagement and learning in educational settings.\n\n\nThis experience has deepened my understanding of educational technology, human-AI interaction, and quantitative research methods, while also giving me opportunities to collaborate across interdisciplinary teams."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ruilin Wu",
    "section": "",
    "text": "Hi, I’m Ruilin Wu! I’m a third-year student at University of California Irvine, majoring in Data Science with a minor in Informatics."
  },
  {
    "objectID": "media/Breast_Cancer_Recurrence_Prediction.html",
    "href": "media/Breast_Cancer_Recurrence_Prediction.html",
    "title": "Introduction",
    "section": "",
    "text": "Final Project: Breast Cancer Recurrence Prediction\nShuyi Chen, Ruilin Wu\n\nIntroduction\nBreast cancer is one of the most common malignancies affecting women worldwide, and its recurrence remains a serious concern, often occurring months or years after initial breast cancer treatment. Various machine learning models have been explored for predicting breast cancer recurrence, from Naive Bayes classifiers to complex deep learning approaches. While advanced models like CNNs and NLP-based systems show high accuracy, they often depend on unstructured data and complex infrastructure. In contrast, Kim et al. (2016) demonstrated that a Naive Bayesian model can effectively predict five-year recurrence, highlighting its clinical potential.\nThis report focuses on applying Bayesian Logistic Regression—an interpretable and widely used method—to evaluate its effectiveness in predicting breast cancer recurrence using a structured clinical dataset, aiming to support transparent and reliable clinical decision-making.\n\n\nData Description\nThe breast cancer dataset was obtained from the University Medical Centre, Institute of Oncology, located in Ljubljana, Yugoslavia. The dataset consists of 286 instances categorized into two distinct outcomes: 201 instances represent cases with no recurrence events, while 85 instances indicate cases with recurrence events. It is important to note that the dataset contains missing values, necessitating proper handling in subsequent analytical and modeling procedures.\nEach instance within the dataset is described by nine attributes, which include both linear and categorical variables. The attributes include age (categorized in decade ranges from 10 to 99 years), menopause status (categorized as less than 40 years, greater or equal to 40 years, or premenopausal), tumor size (categorized in increments of five millimeters, ranging from 0 to 59 mm), the number of involved axillary lymph nodes (categorized in increments of three, ranging from 0 to 39), presence or absence of capsular invasion (binary classification of yes or no), degree of malignancy (ordinal scale from 1 to 3, indicating increasing severity), the affected breast side (left or right), tumor location within breast quadrants (left-upper, left-lower, right-upper, right-lower, or central), and the administration of irradiation therapy (binary classification of yes or no).\n\n\nExploratory Data Analysis\nAfter removing rows with missing values, our dataset contained 277 observations. We also excluded two single-row categories—one instance of invnodes “24-26” and one instance of age “20-29”—since they each occurred only once and could cause modeling or cross-validation issues. This left us with a final total of 275 observations. The dataset shows a moderate imbalance in the outcome variable, with roughly 71% of cases being no-recurrence events and 29% recurrence events (Figure 1). Most patients fall within the 30–69 age range, and the menopausal status is split mainly between “premenopause” and “greater or equal to 40,” while the “less than 40” group remains sparse. The cross-tabulation (Table 1) indicates that most patients in both outcome groups are between 30 and 69 years old, with the highest counts in the 40–59 age ranges.\n\n\nMethodology\nWe fit a Bayesian logistic regression model (using stan_glm() in the rstanarm package) to predict breast cancer recurrence, employing the binomial family with a logit link. Each predictor—age, menopause, tumorsize, invnodes, nodecaps, degmalig, breast, breastquad, and irradiat—was included as a fixed effect. We applied weakly informative normal priors (μ = 0, σ = 2.5) for coefficients and (μ = 0, σ = 5) for the intercept, without imposing overly strong assumptions on effect sizes.\nFour Markov Chain Monte Carlo (MCMC) chains were run for 10,000 iterations each, and we evaluated convergence via the Gelman–Rubin statistic (R-hat) and effective sample size. The posterior predictive check (Figure 2) suggested that the model adequately captured the distribution of observed outcomes, supporting its overall fit to the data. Furthermore, the MCMC density plot (Figure 3) demonstrated well-behaved sampling behavior across all parameters, with consistent overlap between chains and unimodal posterior distributions. After confirming convergence, we extracted 80% credible intervals for the model’s coefficients (and exponentiated these to interpret them as odds ratios). Model performance was assessed by computing predicted probabilities for each observation, then constructing a ROC curve and identifying an optimal classification threshold using Youden’s index (Figure 4). Finally, a 10-fold cross-validation (classification_summary_cv()) was performed at the chosen threshold (0.33) to estimate sensitivity, specificity, and overall accuracy in an out-of-sample context.\n\n\nResults\nAll chains converged satisfactorily, with R-hat and sufficiently large effective sample sizes. The 80% credible intervals for the exponentiated coefficients reveal that invnodes3–5, invnodes6–8, invnodes9–11, and degmalig lie entirely above 1, indicating a higher probability of recurrence compared to their reference categories. In contrast, tumorsize10–14 sits entirely below 1, suggesting lower recurrence odds than the reference tumor‐size bin. Most other predictors, such as age brackets, menopausal status, most tumor‐size categories, have intervals crossing 1, meaning the model cannot rule out either increased or decreased risk given the data—these effects remain uncertain. Finally, the intercept’s exponentiated interval falling far below 1 indicates that, when all predictors are at their reference levels, the baseline odds of recurrence are quite low; other predictors then raise or lower this low baseline as indicated by their respective odds ratios.\nA ROC curve analysis on the entire dataset suggested a 0.33 probability threshold for optimal classification (Figure 4). Applying this threshold in the 10-fold cross-validation produced a sensitivity of roughly 67.1%, specificity of about 71.3%, and an overall accuracy near 69.5%.\nConclusion\nIn the context of this breast cancer dataset, the Bayesian logistic regression model provided a moderate level of predictive power, aligning with expectations for a relatively small clinical dataset. The model’s interpretability is its key advantage: practitioners can directly review posterior intervals and odds ratios to understand how clinical features—particularly tumor size, lymph node involvement, and degree of malignancy—influence breast cancer recurrence risk. While most variables had limited impact or wider credible intervals due to sparse data, the approach still offered transparent risk stratification. Future work might include incorporating additional patient features such as genetic markers or exploring more robust priors to potentially enhance performance.\n\n\nReferences\nKim, Woojae, et al. “Nomogram of Naive Bayesian Model for Recurrence Prediction of Breast Cancer.” Healthcare Informatics Research, vol. 22, no. 2, 30 Apr. 2016, p. 89, https://doi.org/10.4258/hir.2016.22.2.89.\nWang, Hanyin, et al. “Prediction of Breast Cancer Distant Recurrence Using Natural Language Processing and Knowledge-Guided Convolutional Neural Network.” Artificial Intelligence in Medicine, vol. 110, 1 Nov. 2020, p. 101977, https://doi.org/10.1016/j.artmed.2020.101977.\n\n\nAppendix\n\nFigure 1. Distribution of Recurrence Events\n\n\nFigure 2. PP Check Plot\n\nFigure 3. MCMC Density Plot\n\nFigure 4. ROC Curve"
  },
  {
    "objectID": "media/Stats170A_a1.html",
    "href": "media/Stats170A_a1.html",
    "title": "Data Processing",
    "section": "",
    "text": "Shuyi Chen, Ruilin Wu\n\n\nacm_fellows.csv contains 1493 rows and 2 columns, and the column names are name and year. The dataset records the awards from 1994 to 2023. There are no duplicated rows and missing values. However, the following names of the researchers who received the award more than once.\n\nconference_ranking.csv contains 1493 rows and 3 columns, and the column names are Antonym, Name and Rank. Conferences are ranked into 4 levels, A*, A, B, C. There are no duplicate rows and missing values. However, among the A* ranked conferences, three different conferences share the same abbreviation, and the abbreviation ICIS appears three times. As a result, relying solely on abbreviations may lead to ambiguity and potential errors.\n\ncountry-info.csv contains 468 rows and 3 columns, with the column names: institution, region, and countryabbrv. The file has no duplicate rows or missing values. Since U.S. institutions are excluded, the majority of institutions are from Europe, totaling 239 institutions. In contrast, Africa has the fewest institutions, with only 3 entries.\n\ncsrankings.csv contains 30400 rows and 4 columns, with the column names: name, affiliation, homepage and scholarid. The dataset has no duplicate rows or missing values. However, when considering only the scholarid column, 10401 scholar IDs appear more than once.\n\ndata.csv contains 1827 rows and 26 columns. The number of total missing values is 8727. Ten columns have different counts of missing values. These missing values may pose challenges in obtaining a complete understanding of the represented CS schools.\n\ndblp-aliases.csv contains 100987 rows and 2 columns, with column names: alias and name. While there are no missing values, the dataset includes 3 duplicate rows.\n\nfield_conference.csv contains 77 rows and 3 columns with the column names: major, field and conference. The major is consistently Computer Science, but the dataset includes 27 distinct fields spanning various conferences.\n\ngenerated-author-info.csv contains 239169 rows and 6 columns, with column names: name, dept, area, count, adjustedcount and year. Within this large dataset, it has no duplicate rows or missing values. From the trend of adjustedcount over the years, showing a significant increase in research publications after 2000.\n\ngeolocation.csv contains 570 rows and 3 columns, with column names: institution, latitude and longitude. The dataset has no duplicate rows or missing values. The latitude and longitude values span both negative and positive ranges, indicating a global coverage. This suggests that CS rankings vary across different countries worldwide.\n\nturing.csv contains 89 rows and 2 columns, with column names: name and year. The dataset has no duplicate rows or missing values. The award years range from 1966 to 2023. Notably, six researchers received the award in 2002, making it one of the most awarded years.\n\n\n\n\nWe processed all the datasets by reading CSV files, transforming specific columns, and storing them in an SQLite database. One key transformation we performed was splitting names into first_name, middle_name, and last_name for datasets like csrankings.csv and generated-author-info.csv. We achieved this using strsplit(df$name, “\\\\s+”), which separated names based on spaces. The first element was assigned as first_name, while the middle portion was combined into middle_name if present. The last element was usually assigned as last_name, but if the last token was numeric, we used the second-to-last word instead to ensure proper name extraction.\nAdditionally, we enhanced the conference_ranking.csv dataset by categorizing conferences based on their affiliations with ACM, IEEE, or both. Once we completed the transformations, we wrote all datasets into an SQLite database using dbWriteTable(), with queries verifying successful data storage. Lastly for this task, we used dbListTables(con) to confirm that all tables have been created, ensuring a structured and organized database for further analysis.\nconference_ranking.csv (added academic society)\n\ncsrankings.csv (the names were separated into its component first name, middle name and last name values)\n\n\ngenerated-author-info.csv (the names were separated into its component first name, middle name and last name values)\n\nacm-fellows.csv\n\n\n\ncountry-info.csv\n\ndata.csv\n\n\n\n(and 16-26 of 26 columns are not showed for space purpose)\ndblp-aliases.csv\n\nfield_conference.csv\n\ngeolocation.csv\n\nturing.csv\n\n\n\n\n\n\n\n\nThe first 10 names from the missing authors list, sorted alphabetically.\n\ngenerated_author_info\n\nacm_fellows\n\nturing\n\n\n\n\nWe combined the three missing authors lists into a single dataframe with distinct names (824 missing names in total). Then we further splitted the name column into first name, middle name, and last name.\n\nFinally, we inserted name, first_name, middle_name, and last_name from missing authors dataframe into csrankings table, other fields values are by default NULL.\n\n\n\n\n\n\n\n\n\nWe use a two-step approach to determine whether two (or more) records from csrankings table represent the same author. First, we define a function that checks if two records have the same last and first name and compatible middle names—either an exact match or one name being an initial matching the first letter of the other. For instance, “John P. Smith” and “John Paul Smith” match if they share the same last name, have the same first name, and either matching or initial-matching middle names; we also consider two records duplicates if one or both are missing a middle name but the first and last names match (e.g., “John Smith” and “John Paul Smith”). Second, once we identify groups of authors who are duplicates, we pick one “most complete” name—typically the one with the longest middle name—to serve as the canonical reference (the “synonym”) for everyone in that group. This ensures, for example, that “John Smith,” “John P Smith,” and “John Paul Smith” all unify under “John Paul Smith.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following is the representative subsets of the duplicate_author table.\n\n\nThere are a total of 5705 rows of duplicate names being found based on our implementation.\n\n\n\n\nWe retrieved the csrankings and duplicate_author tables from the database, then joined them to replace any duplicate names with their canonical synonyms, standardizing the “name” column. It groups the updated records by this canonical name and merges duplicate rows by selecting, for each attribute, the longest (most complete) value, then writes the resulting clean table back to the database. The cleaned cs_rankings have 28115 rows, compared with cs_rankings 31224 rows, we found and merged 3,109 duplicate rows.\n\n\n\n\nWe update the generated_author_info table by replacing duplicate author names with their canonical synonyms as identified in the duplicate_author table.\nWe deliberately avoid merging rows because we want to preserve the original structure where each row represents a single count entry (e.g., one paper). Merging records would aggregate counts and potentially lose the granularity of the data. By simply replacing the names, we standardize author identifiers across tables while retaining the original row-level detail for further analysis. Therefore, the generated_clean retains 239169 rows.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask 4.1\nSQL Query:\nSELECT\ng.name AS author,\ng.dept AS institution,\nSUM(g.count) AS a_star_publication\nFROM generated_author_info_clean AS g\nJOIN conference_ranking AS c\nON LOWER(g.area) = LOWER(c.Antonym)\nWHERE c.Rank = ‘A*’\nAND g.year BETWEEN 2010 AND 2024\nGROUP BY g.name, g.dept\nORDER BY a_star_publication DESC, author ASC, institution ASC\nLIMIT 100;\nOutput:\nFrom the above SQL statement, we have generated top 100 authors. The following screenshot displays the top 10 of them.\n\n\n\n\n\n\n\n\n\nSQL Query:\nWITH RankedInstitutions AS (\nSELECT\nCOALESCE(fc.field, ‘Unknown Field’) AS cs_field,\ng.dept AS institution_name,\nCOUNT(*) AS a_star_publications,\nRANK() OVER (\nPARTITION BY COALESCE(fc.field, ‘Unknown Field’)\nORDER BY COUNT(*) DESC, g.dept ASC\n) AS rank_position\nFROM generated_author_info_clean g\nJOIN conference_ranking c\nON LOWER(g.area) = LOWER(c.Antonym)\nLEFT JOIN field_conference fc\nON LOWER(g.area) LIKE ‘%’ || LOWER(fc.conference) || ‘%’ – Substring matching\nWHERE c.Rank = ‘A*’\nGROUP BY COALESCE(fc.field, ‘Unknown Field’), g.dept\n)\nSELECT\ncs_field,\ninstitution_name,\na_star_publications\nFROM RankedInstitutions\nWHERE rank_position &lt;= 10\nORDER BY cs_field ASC, a_star_publications DESC, institution_name ASC;\nOutput: From the above SQL statement, we have generated top 10 institutions in each field. The total number of fields is 17."
  },
  {
    "objectID": "media/Stats170A_a1.html#task-1-data-exploration-and-discovery",
    "href": "media/Stats170A_a1.html#task-1-data-exploration-and-discovery",
    "title": "Data Processing",
    "section": "",
    "text": "acm_fellows.csv contains 1493 rows and 2 columns, and the column names are name and year. The dataset records the awards from 1994 to 2023. There are no duplicated rows and missing values. However, the following names of the researchers who received the award more than once.\n\nconference_ranking.csv contains 1493 rows and 3 columns, and the column names are Antonym, Name and Rank. Conferences are ranked into 4 levels, A*, A, B, C. There are no duplicate rows and missing values. However, among the A* ranked conferences, three different conferences share the same abbreviation, and the abbreviation ICIS appears three times. As a result, relying solely on abbreviations may lead to ambiguity and potential errors.\n\ncountry-info.csv contains 468 rows and 3 columns, with the column names: institution, region, and countryabbrv. The file has no duplicate rows or missing values. Since U.S. institutions are excluded, the majority of institutions are from Europe, totaling 239 institutions. In contrast, Africa has the fewest institutions, with only 3 entries.\n\ncsrankings.csv contains 30400 rows and 4 columns, with the column names: name, affiliation, homepage and scholarid. The dataset has no duplicate rows or missing values. However, when considering only the scholarid column, 10401 scholar IDs appear more than once.\n\ndata.csv contains 1827 rows and 26 columns. The number of total missing values is 8727. Ten columns have different counts of missing values. These missing values may pose challenges in obtaining a complete understanding of the represented CS schools.\n\ndblp-aliases.csv contains 100987 rows and 2 columns, with column names: alias and name. While there are no missing values, the dataset includes 3 duplicate rows.\n\nfield_conference.csv contains 77 rows and 3 columns with the column names: major, field and conference. The major is consistently Computer Science, but the dataset includes 27 distinct fields spanning various conferences.\n\ngenerated-author-info.csv contains 239169 rows and 6 columns, with column names: name, dept, area, count, adjustedcount and year. Within this large dataset, it has no duplicate rows or missing values. From the trend of adjustedcount over the years, showing a significant increase in research publications after 2000.\n\ngeolocation.csv contains 570 rows and 3 columns, with column names: institution, latitude and longitude. The dataset has no duplicate rows or missing values. The latitude and longitude values span both negative and positive ranges, indicating a global coverage. This suggests that CS rankings vary across different countries worldwide.\n\nturing.csv contains 89 rows and 2 columns, with column names: name and year. The dataset has no duplicate rows or missing values. The award years range from 1966 to 2023. Notably, six researchers received the award in 2002, making it one of the most awarded years."
  },
  {
    "objectID": "media/Stats170A_a1.html#task-2-data-loading-and-transformation",
    "href": "media/Stats170A_a1.html#task-2-data-loading-and-transformation",
    "title": "Data Processing",
    "section": "",
    "text": "We processed all the datasets by reading CSV files, transforming specific columns, and storing them in an SQLite database. One key transformation we performed was splitting names into first_name, middle_name, and last_name for datasets like csrankings.csv and generated-author-info.csv. We achieved this using strsplit(df$name, “\\\\s+”), which separated names based on spaces. The first element was assigned as first_name, while the middle portion was combined into middle_name if present. The last element was usually assigned as last_name, but if the last token was numeric, we used the second-to-last word instead to ensure proper name extraction.\nAdditionally, we enhanced the conference_ranking.csv dataset by categorizing conferences based on their affiliations with ACM, IEEE, or both. Once we completed the transformations, we wrote all datasets into an SQLite database using dbWriteTable(), with queries verifying successful data storage. Lastly for this task, we used dbListTables(con) to confirm that all tables have been created, ensuring a structured and organized database for further analysis.\nconference_ranking.csv (added academic society)\n\ncsrankings.csv (the names were separated into its component first name, middle name and last name values)\n\n\ngenerated-author-info.csv (the names were separated into its component first name, middle name and last name values)\n\nacm-fellows.csv"
  },
  {
    "objectID": "media/Stats170A_a1.html#section",
    "href": "media/Stats170A_a1.html#section",
    "title": "Data Processing",
    "section": "",
    "text": "country-info.csv\n\ndata.csv\n\n\n\n(and 16-26 of 26 columns are not showed for space purpose)\ndblp-aliases.csv\n\nfield_conference.csv\n\ngeolocation.csv\n\nturing.csv"
  },
  {
    "objectID": "media/Stats170A_a1.html#task-3.1",
    "href": "media/Stats170A_a1.html#task-3.1",
    "title": "Data Processing",
    "section": "",
    "text": "The first 10 names from the missing authors list, sorted alphabetically.\n\ngenerated_author_info\n\nacm_fellows\n\nturing\n\n\n\n\nWe combined the three missing authors lists into a single dataframe with distinct names (824 missing names in total). Then we further splitted the name column into first name, middle name, and last name.\n\nFinally, we inserted name, first_name, middle_name, and last_name from missing authors dataframe into csrankings table, other fields values are by default NULL.\n\n\n\n\n\n\n\n\n\nWe use a two-step approach to determine whether two (or more) records from csrankings table represent the same author. First, we define a function that checks if two records have the same last and first name and compatible middle names—either an exact match or one name being an initial matching the first letter of the other. For instance, “John P. Smith” and “John Paul Smith” match if they share the same last name, have the same first name, and either matching or initial-matching middle names; we also consider two records duplicates if one or both are missing a middle name but the first and last names match (e.g., “John Smith” and “John Paul Smith”). Second, once we identify groups of authors who are duplicates, we pick one “most complete” name—typically the one with the longest middle name—to serve as the canonical reference (the “synonym”) for everyone in that group. This ensures, for example, that “John Smith,” “John P Smith,” and “John Paul Smith” all unify under “John Paul Smith.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following is the representative subsets of the duplicate_author table.\n\n\nThere are a total of 5705 rows of duplicate names being found based on our implementation.\n\n\n\n\nWe retrieved the csrankings and duplicate_author tables from the database, then joined them to replace any duplicate names with their canonical synonyms, standardizing the “name” column. It groups the updated records by this canonical name and merges duplicate rows by selecting, for each attribute, the longest (most complete) value, then writes the resulting clean table back to the database. The cleaned cs_rankings have 28115 rows, compared with cs_rankings 31224 rows, we found and merged 3,109 duplicate rows.\n\n\n\n\nWe update the generated_author_info table by replacing duplicate author names with their canonical synonyms as identified in the duplicate_author table.\nWe deliberately avoid merging rows because we want to preserve the original structure where each row represents a single count entry (e.g., one paper). Merging records would aggregate counts and potentially lose the granularity of the data. By simply replacing the names, we standardize author identifiers across tables while retaining the original row-level detail for further analysis. Therefore, the generated_clean retains 239169 rows."
  },
  {
    "objectID": "media/Stats170A_a1.html#task-4-analysis",
    "href": "media/Stats170A_a1.html#task-4-analysis",
    "title": "Data Processing",
    "section": "",
    "text": "Task 4.1\nSQL Query:\nSELECT\ng.name AS author,\ng.dept AS institution,\nSUM(g.count) AS a_star_publication\nFROM generated_author_info_clean AS g\nJOIN conference_ranking AS c\nON LOWER(g.area) = LOWER(c.Antonym)\nWHERE c.Rank = ‘A*’\nAND g.year BETWEEN 2010 AND 2024\nGROUP BY g.name, g.dept\nORDER BY a_star_publication DESC, author ASC, institution ASC\nLIMIT 100;\nOutput:\nFrom the above SQL statement, we have generated top 100 authors. The following screenshot displays the top 10 of them.\n\n\n\n\n\n\n\n\n\nSQL Query:\nWITH RankedInstitutions AS (\nSELECT\nCOALESCE(fc.field, ‘Unknown Field’) AS cs_field,\ng.dept AS institution_name,\nCOUNT(*) AS a_star_publications,\nRANK() OVER (\nPARTITION BY COALESCE(fc.field, ‘Unknown Field’)\nORDER BY COUNT(*) DESC, g.dept ASC\n) AS rank_position\nFROM generated_author_info_clean g\nJOIN conference_ranking c\nON LOWER(g.area) = LOWER(c.Antonym)\nLEFT JOIN field_conference fc\nON LOWER(g.area) LIKE ‘%’ || LOWER(fc.conference) || ‘%’ – Substring matching\nWHERE c.Rank = ‘A*’\nGROUP BY COALESCE(fc.field, ‘Unknown Field’), g.dept\n)\nSELECT\ncs_field,\ninstitution_name,\na_star_publications\nFROM RankedInstitutions\nWHERE rank_position &lt;= 10\nORDER BY cs_field ASC, a_star_publications DESC, institution_name ASC;\nOutput: From the above SQL statement, we have generated top 10 institutions in each field. The total number of fields is 17."
  }
]